{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "tutorial.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ni0OwMZvvLXM",
        "colab_type": "text"
      },
      "source": [
        "## Introduction to overcooked_ai\n",
        "\n",
        "Overcooked-AI is a benchmark environment for fully cooperative multi-agent performance, based on the wildly popular video game [Overcooked](http://www.ghosttowngames.com/overcooked/). \n",
        "\n",
        "The goal of the game is to deliver soups as fast as possible. Each soup requires placing up to 3 ingredients in a pot, waiting for the soup to cook, and then having an agent pick up the soup and delivering it. The agents should split up tasks on the fly and coordinate effectively in order to achieve high reward.\n",
        "\n",
        "You can **try out the game [here](https://humancompatibleai.github.io/overcooked-demo/)** (playing with some previously trained DRL agents). To play with your own trained agents using this interface, you can use [this repo](https://github.com/HumanCompatibleAI/overcooked-demo). To run human-AI experiments, check out [this repo](https://github.com/HumanCompatibleAI/overcooked-hAI-exp). You can find some human-human gameplay data already collected [here](https://github.com/HumanCompatibleAI/human_aware_rl/tree/master/human_aware_rl/data/human/anonymized).\n",
        "The agent evaluator is an object used to evaluate different agents.\n",
        "\n",
        "Check out [this repo](https://github.com/HumanCompatibleAI/human_aware_rl) for the DRL implementations compatible with the environment and reproducible results to our paper: *[On the Utility of Learning about Humans for Human-AI Coordination](https://arxiv.org/abs/1910.05789)* (also see our [blog post](https://bair.berkeley.edu/blog/2019/10/21/coordination/))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Vq1QzF6vLXO",
        "colab_type": "text"
      },
      "source": [
        "# Setup\n",
        "Run cell below only if you did not installed overcooked_ai yet (e.g. when using this notebook in google collab) to install newest version of overcooked_ai from github repository."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKuYtq2ivLXP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "9d01a7f7-e501-490a-bfce-efc92e84f36e"
      },
      "source": [
        "!pip install --progress-bar off git+https://github.com/HumanCompatibleAI/overcooked_ai.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/HumanCompatibleAI/overcooked_ai.git\n",
            "  Cloning https://github.com/HumanCompatibleAI/overcooked_ai.git to /tmp/pip-req-build-eb_ycj9x\n",
            "  Running command git clone -q https://github.com/HumanCompatibleAI/overcooked_ai.git /tmp/pip-req-build-eb_ycj9x\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from overcooked-ai==1.0.4) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from overcooked-ai==1.0.4) (4.41.1)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (from overcooked-ai==1.0.4) (0.17.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from overcooked-ai==1.0.4) (5.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym->overcooked-ai==1.0.4) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym->overcooked-ai==1.0.4) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym->overcooked-ai==1.0.4) (1.5.0)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->overcooked-ai==1.0.4) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->overcooked-ai==1.0.4) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->overcooked-ai==1.0.4) (50.3.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->overcooked-ai==1.0.4) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->overcooked-ai==1.0.4) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->overcooked-ai==1.0.4) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->overcooked-ai==1.0.4) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->overcooked-ai==1.0.4) (4.3.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym->overcooked-ai==1.0.4) (0.16.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->overcooked-ai==1.0.4) (0.6.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->overcooked-ai==1.0.4) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->overcooked-ai==1.0.4) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->overcooked-ai==1.0.4) (0.2.0)\n",
            "Building wheels for collected packages: overcooked-ai\n",
            "  Building wheel for overcooked-ai (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overcooked-ai: filename=overcooked_ai-1.0.4-cp36-none-any.whl size=2394778 sha256=bb8ff8ce0a6e0ac83780f4e281b4a6f108dd126ad3a158ca30a74d3a7f261711\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-mfoer51s/wheels/2a/7f/1d/7cb1dc49cbbf5b9a8e462507c7c30499ba82a4436e5aa12ced\n",
            "Successfully built overcooked-ai\n",
            "Installing collected packages: overcooked-ai\n",
            "Successfully installed overcooked-ai-1.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3QU6rMDvLXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# all imports used in this tutorial, run this if you want to jump to different sections and run only selected cells\n",
        "import numpy as np\n",
        "from overcooked_ai_py.mdp.actions import Action, Direction\n",
        "from overcooked_ai_py.agents.agent import Agent, AgentPair, StayAgent\n",
        "from overcooked_ai_py.agents.benchmarking import AgentEvaluator, LayoutGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyH7twYBvLXZ",
        "colab_type": "text"
      },
      "source": [
        "## Agent evaluator introduction\n",
        "Most easy way to start using overcooked_ai is to use agent evaluator object that lets you to run agents on the choosen layouts. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "5Em0Rk4ZvLXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from overcooked_ai_py.agents.benchmarking import AgentEvaluator, LayoutGenerator\n",
        "mdp_gen_params = {\"layout_name\": 'cramped_room'}\n",
        "mdp_fn = LayoutGenerator.mdp_gen_fn_from_dict(mdp_gen_params)\n",
        "env_params = {\"horizon\": 1000}\n",
        "agent_eval = AgentEvaluator(env_params=env_params, mdp_fn=mdp_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZP_hkyY4vLXe",
        "colab_type": "text"
      },
      "source": [
        "To create agent evaluator you need to supply 2 parameters: `mdp_fn` and `env_params`.  \n",
        "`mdp_fn` is function that returns OvercookedGridworld object that resolves interactions of agents with environemnt. The quickest method to create valid `mdp_fn` is to supply dict with layout name to `LayoutGenerator.mdp_gen_fn_from_dict`. More on generation of layouts later.  \n",
        "`env_params` is a dict with additional options. Most imporant thing to supply here is `horizon` key that indicates how many timesteps will be made in each episode."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaiX7V0IvLXf",
        "colab_type": "text"
      },
      "source": [
        "The central method of the AgentEvaluator object is evaluate_agent_pair that runs 2 agents on the chosen layout.\n",
        "Other methods can call evaluate_agent_pair method with preexisting agents. Let's run random agents 5 times and see the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "bSuRt6zavLXg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "2ae689f3-9688-4ac0-b405-fd20dd56a353"
      },
      "source": [
        "# does random actions\n",
        "trajectory_random_pair = agent_eval.evaluate_random_pair(num_games=5)\n",
        "print(\"Random pair rewards\", trajectory_random_pair[\"ep_returns\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Recomputing motion planner due to: [Errno 2] No such file or directory: '/usr/local/lib/python3.6/dist-packages/overcooked_ai_py/data/planners/cramped_room_mp.pkl'\n",
            "Computing MotionPlanner to be saved in /usr/local/lib/python3.6/dist-packages/overcooked_ai_py/data/planners/cramped_room_mp.pkl\n",
            "It took 0.04822421073913574 seconds to create mp\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Avg rew: 0.00 (std: 0.00, se: 0.00); avg len: 1000.00; : 100%|██████████| 5/5 [00:01<00:00,  3.07it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Skipping trajectory consistency checking because MDP was recognized as variable. Trajectory consistency checking is not yet supported for variable MDPs.\n",
            "Random pair rewards [0 0 0 0 0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUJKC6KTvLXk",
        "colab_type": "text"
      },
      "source": [
        "## Custom layouts\n",
        "Besides premade layouts found in the [layout directory](https://github.com/HumanCompatibleAI/overcooked_ai/tree/master/src/overcooked_ai_py/data/layouts) you can create your own layouts to run agents on. Lets first look at example layout:\n",
        "```\n",
        "{\n",
        "    \"grid\":  \"\"\"XXXPPXXX\n",
        "                X  2   X\n",
        "                D XXXX S\n",
        "                X  1   X\n",
        "                XXXOOXXX\"\"\",\n",
        "    \"start_order_list\": None,\n",
        "    \"cook_time\": 20,\n",
        "    \"num_items_for_soup\": 3,\n",
        "    \"delivery_reward\": 20,\n",
        "    \"rew_shaping_params\": None\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNm8NedcvLXk",
        "colab_type": "text"
      },
      "source": [
        "Layout territory is defined by grid. Every character is one tile. Available tiles are:\n",
        "- empty space - ' '\n",
        "- counter - 'X'\n",
        "- onion dispenser - 'O'\n",
        "- tomato dispenser - 'T'\n",
        "- pot (place where players cook soup from onions and tomatoes) - 'P' \n",
        "- dish dispenser - 'D '\n",
        "- serving location - 'S'\n",
        "- player starting location - number  \n",
        "  \n",
        "You can save layout in ovecooked_ai/overcooked_ai_py/data/layouts directory and then run agent evaluator AgentEvaluator({\"layout_name\": layout_name}) where layout_name is filename without `.layout` extension.  \n",
        "You can also generate random, but valid grids in automated way. Lets create one and run agents on it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzcyIjmSvLXl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "0fbc31e4-0b47-4f8d-be14-e03333a6dc30"
      },
      "source": [
        "mdp_gen_params = {\"inner_shape\": (7,7),\n",
        "                \"prop_empty\":0.2, # proportion of empty space in generated layout\n",
        "                \"prop_feats\":0.8, # proportion of counters with features on them\n",
        "                \"display\": False,\n",
        "                \"start_all_orders\": # list of recipes that can be delived\n",
        "                   [{ \"ingredients\" : [\"onion\", \"onion\", \"onion\"]},\n",
        "                    { \"ingredients\" : [\"onion\", \"onion\"]},\n",
        "                    { \"ingredients\" : [\"onion\"]}],\n",
        "                # (optional param) reward for delivering recipes (for every recipe in start_all_orders)\n",
        "                \"recipe_values\" : [20, 9, 4], \n",
        "                # (optional param) cooking time of recipes (for every recipe in start_all_orders)\n",
        "                \"recipe_times\" : [20, 15, 10]\n",
        "                 }\n",
        "\n",
        "env_params =  {\"horizon\": 500}\n",
        "\n",
        "mdp_fn = LayoutGenerator.mdp_gen_fn_from_dict(mdp_gen_params, outer_shape=(7, 7))\n",
        "agent_eval = AgentEvaluator(env_params=env_params, mdp_fn=mdp_fn)\n",
        "\n",
        "trajectory_random_pair = agent_eval.evaluate_random_pair(num_games=10)\n",
        "print(\"Random pair rewards\", trajectory_random_pair[\"ep_returns\"])\n",
        "\n",
        "def pretty_grid(grid):\n",
        "    return \"\\n\".join(\"\".join(line) for line in grid)\n",
        "\n",
        "print(\"\\nGenerated grid:\\n\" + pretty_grid(trajectory_random_pair[\"mdp_params\"][0][\"terrain\"]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Recomputing motion planner due to: [Errno 2] No such file or directory: '/usr/local/lib/python3.6/dist-packages/overcooked_ai_py/data/planners/XXPPPSX|O   1 X|X     P|P   D2O|P    DX|D XO  S|XSXXOPX_mp.pkl'\n",
            "Computing MotionPlanner to be saved in /usr/local/lib/python3.6/dist-packages/overcooked_ai_py/data/planners/XXPPPSX|O   1 X|X     P|P   D2O|P    DX|D XO  S|XSXXOPX_mp.pkl\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Avg rew: 0.00 (std: 0.00, se: 0.00); avg len: 500.00; :  10%|█         | 1/10 [00:01<00:13,  1.47s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "It took 1.2998719215393066 seconds to create mp\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Avg rew: 0.40 (std: 1.20, se: 0.38); avg len: 500.00; : 100%|██████████| 10/10 [00:03<00:00,  3.10it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Skipping trajectory consistency checking because MDP was recognized as variable. Trajectory consistency checking is not yet supported for variable MDPs.\n",
            "Random pair rewards [0 0 0 0 4 0 0 0 0 0]\n",
            "\n",
            "Generated grid:\n",
            "XXPPPSX\n",
            "O     X\n",
            "X     P\n",
            "P   D O\n",
            "P    DX\n",
            "D XO  S\n",
            "XSXXOPX\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfwExnpgvLXp",
        "colab_type": "text"
      },
      "source": [
        "## Custom agents\n",
        "We can also run own custom agents to see how they are would work. Lets re-create agent doing random actions on out own."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4TMnuEUvLXq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "6b6d5778-c410-4e0b-c6a4-8916dfd640d3"
      },
      "source": [
        "import numpy as np\n",
        "from overcooked_ai_py.mdp.actions import Action, Direction\n",
        "from overcooked_ai_py.agents.agent import Agent, AgentPair\n",
        "\n",
        "class CustomRandomAgent(Agent):\n",
        "    \"\"\"\n",
        "    An agent that randomly picks motion actions.\n",
        "    NOTE: Does not perform interact actions, unless specified\n",
        "    \"\"\"   \n",
        "    def action(self, state):\n",
        "        action_probs = np.zeros(Action.NUM_ACTIONS)\n",
        "        legal_actions = Action.ALL_ACTIONS\n",
        "        legal_actions_indices = np.array([Action.ACTION_TO_INDEX[motion_a] for motion_a in legal_actions])\n",
        "        action_probs[legal_actions_indices] = 1 / len(legal_actions_indices)\n",
        "        return Action.sample(action_probs), {\"action_probs\": action_probs}\n",
        "\n",
        "    def actions(self, states, agent_indices):\n",
        "        return [self.action(state) for state in states]\n",
        "\n",
        "\n",
        "agent_pair = AgentPair(CustomRandomAgent(), CustomRandomAgent())\n",
        "mdp_gen_params = {\"layout_name\": 'cramped_room'}\n",
        "mdp_fn = LayoutGenerator.mdp_gen_fn_from_dict(mdp_gen_params)\n",
        "env_params = {\"horizon\": 1000}\n",
        "agent_eval = AgentEvaluator(env_params=env_params, mdp_fn=mdp_fn)\n",
        "trajectory_custom_random_pair = agent_eval.evaluate_agent_pair(agent_pair, num_games=4)\n",
        "print(\"Custom random pair rewards\", trajectory_custom_random_pair[\"ep_returns\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Avg rew: 10.00 (std: 10.00, se: 5.00); avg len: 1000.00; : 100%|██████████| 4/4 [00:01<00:00,  2.87it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Skipping trajectory consistency checking because MDP was recognized as variable. Trajectory consistency checking is not yet supported for variable MDPs.\n",
            "Custom random pair rewards [20 20  0  0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pn_leFAQvLXv",
        "colab_type": "text"
      },
      "source": [
        "CustomRandomAgent is lightweight version of RandomAgent from overcooked_ai_py.agents.agent module. ```trajectory_custom_random_pair = agent_eval.evaluate_agent_pair(agent_pair)``` have same effect as ```agent_eval.evaluate_random_pair()```."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po0l03DfvLXv",
        "colab_type": "text"
      },
      "source": [
        "## Single player variant\n",
        "If you want to make single player variant you need to set one of the agents to stay and do nothing. `StayAgent` is a such agent. It is good to take choose layout where every player is not blocking crucial path to resource e.g. only onion dispenser on the layout."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2nVTznyvLXw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "922e579a-3a0a-4fff-c2ae-ae4d94246f57"
      },
      "source": [
        "from overcooked_ai_py.agents.agent import StayAgent, RandomAgent\n",
        "mdp_gen_params = {\"layout_name\": 'five_by_five'}\n",
        "mdp_fn = LayoutGenerator.mdp_gen_fn_from_dict(mdp_gen_params)\n",
        "env_params = {\"horizon\": 500}\n",
        "agent_eval = AgentEvaluator(env_params=env_params, mdp_fn=mdp_fn)\n",
        "single_agent_pair = AgentPair(RandomAgent(all_actions=True), StayAgent())\n",
        "\n",
        "trajectory_single_agent = agent_eval.evaluate_agent_pair(single_agent_pair, num_games=10)\n",
        "print(\"single agent rewards\", trajectory_single_agent[\"ep_returns\"])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Avg rew: 0.00 (std: 0.00, se: 0.00); avg len: 500.00; :  10%|█         | 1/10 [00:00<00:01,  5.44it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Recomputing motion planner due to: [Errno 2] No such file or directory: '/usr/local/lib/python3.6/dist-packages/overcooked_ai_py/data/planners/five_by_five_mp.pkl'\n",
            "Computing MotionPlanner to be saved in /usr/local/lib/python3.6/dist-packages/overcooked_ai_py/data/planners/five_by_five_mp.pkl\n",
            "It took 0.08415436744689941 seconds to create mp\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Avg rew: 0.00 (std: 0.00, se: 0.00); avg len: 500.00; : 100%|██████████| 10/10 [00:01<00:00,  7.59it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Skipping trajectory consistency checking because MDP was recognized as variable. Trajectory consistency checking is not yet supported for variable MDPs.\n",
            "single agent rewards [0 0 0 0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}